<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>AI-HRI</title>
    <meta name="viewport" content="width=device-width; initial-scale=1.0; maximum-scale=1.0;">

    <!-- Some custom styles to make things pretty. -->
    <link rel="stylesheet" type="text/css" href="https://rawgithub.com/tilomitra/prettypages/gh-pages/ui.css">



    <!-- Modify header colors here to customize the look and feel of the site-->
    <style>

        .header {
            background: rgb(0, 60, 120);
         }
        .header h1 {
            font-size:200%;
            color: white;
        }
        .header h2, .header h3 {
            font-weight:300;
            margin:0;
            color: #6DF7BD;
        }

        #past_aihri_links {
            font-size: 120%;
            background: rgb(18, 15, 66);
            color: white;
            padding: 10px 0px 10px 0px;
            text-align: center;
        }
        #past_aihri_links a {
            color: white;
            text-decoration: underline;
        }
        #past_aihri_links a:hover {
            font-weight: bold;
        }

        div.framed {
            padding-top: 15px;
            padding-bottom: 15px;
            font-size: 16px;
            border-bottom: 2px solid black;
            border-top: 2px solid black;
        }

        div.framed li {
            font-size: 18px;
        }

        div.program {
            font-size: 16px;
        }

        .main {
            margin-top: 30px; /* Add a top margin to avoid content overlay */
            margin-left: 40px;
            margin-right: 40px;
        }

        .navbar {
            //overflow: hidden;
            //background-color: rgb(18, 15, 66);
            position: fixed; /* Set the navbar to fixed position */
            top: 0px; /* Position the navbar at the top of the page */
            left: 40px; // width: 100%; /* Full width */
            right: 40px; // width: 100%; /* Full width */
            font-size: 135%;
            padding-top: 10px;
            padding-bottom: 10px;
            padding-left: 10px;
            padding-right: 50px;
            //background-clip: content-box;
            box-shadow: inset 0 0 0 50px rgb(18, 15, 66);

        }

        .navbar a {
            background: rgb(18, 15, 66);
        }

        .navbar a:hover {
            font-weight: bold;
            background: rgb(18, 15, 66);
            box-shadow: inset 0 0 0 50px rgb(18, 15, 66);
        }

        img.adaptive {
            width: 30%;
            height: auto;
        }

     </style>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-64202401-1', 'auto');
      ga('send', 'pageview');

    </script>

</head>

<body class='main'>

    <div id="headerMenu" class="navbar">

        &nbsp;&nbsp;&nbsp; AI-HRI 2020 &nbsp;&nbsp;&nbsp;

            <a href="#home">&nbsp;&nbsp;  Home  &nbsp;&nbsp;  </a>
            <a href="#dates">&nbsp;&nbsp;  Dates & Submission  &nbsp;&nbsp;  </a>
            <!-- a href="#submission">&nbsp;&nbsp;  Submission &nbsp;&nbsp; </a -->
            <a href="#diversity">&nbsp;&nbsp;  Diversity & Inclusion  &nbsp;&nbsp;  </a>
            <!-- a href="#papers">&nbsp;&nbsp;  Papers &nbsp;&nbsp; </a -->
            <a href="#program">&nbsp;&nbsp;  Program  &nbsp;&nbsp;  </a>
            <a href="#committee">&nbsp;&nbsp;  Organizers  &nbsp;&nbsp;  </a>

    </div>

<div>
    <br><br><br>
    <center>
    <img src="images/aaai.jpg" height="100" /> <br><br><br>
    </center>
</div>

<div class="header">
<center>
    <img class="adaptive" src="images/aihri_3_800w_darkbg.png" /> <br>

        <h1>Artificial Intelligence for Human-Robot Interaction: <br>Trust & Explainability in Artificial Intelligence
 for Human-Robot Interaction</h1><br/><br/>

        <h2><a style="color: #CDCDA7; text-decoration: underline;" target="_blank" href="https://aaai.org/Symposia/Fall/fss20.php">AAAI Fall Symposium Series</a></h2><br/><br/>
        <h3 style="color: #DDDDA7;"><del>Washington, DC,</del> November 13-14, 2020</h3><br/>
        <h3 style="color: #DDDDA7;"><del>At the Westin Arlington Gateway in Arlington, Virginia, USA.</del></h3><br/>
</center>
</div>



<div class="content">


<p id="home">

<h2>Updates</h2>
<p>  The 2020 AI-HRI symposium will take place virtually; details to follow.</p>
<p>
  We have confirmed our invited speakers!
  <b><a href="https://interactive.mit.edu/about/people/julie">Julie Shah</a>, <a href="https://www.uu.nl/staff/MMAdeGraaf">Maartje de Graaf</a>, and <a href="https://vivo.brown.edu/display/bmalle">Bertram F. Malle</a></b> will give talks at AI-HRI 2020:
</p>

<h2>Introduction</h2>

<p>
The Artificial Intelligence (AI) for Human-Robot Interaction (HRI) Symposium has been a successful venue of discussion and collaboration since 2014. During that time, the sub-topics of trust and explainability in robotics have been rapidly growing, with major research efforts at universities and laboratories across the world.</p><p>
Trust is generally believed that trust is crucial for adoption of both AI and robotics, particularly when transitioning technologies from the lab to industrial, social, and consumer applications.  Enabling a robot to provide explanations is one approach to fostering this trust.</p><p>
Over the course of the two-day meeting, we will host a collaborative
 forum for discussion of current efforts in trust for AI-HRI, with a sub-session focused on the related topic of explainable AI (XAI) for HRI. Additionally, the symposium will include other topics related to AI for HRI.
</p>

<h3>Topics</h3>

<ul>
<li>Trust and Explainability in HRI
<li>Architectures and systems supporting autonomous HRI
<li>Interactive task learning
<li>Interactive dialog systems and natural language
<li>Field studies, experimental, and empirical HRI
<li>Tools for autonomous HRI
<li>Robot planning and decision-making
<li>Ethics in HRI
<li>AI for social robots
<li>Fielding and deployment, and experimentation for autonomous robots
<li>Knowledge representation and reasoning to support HRI and robot tasking
</ul>


<!--<h2>Format</h2>

<p>
In addition to oral and poster presentations of accepted papers, the
symposium will include panel discussions, position talks, keynote
presentations, and a hack session with ample time for networking.
</p>

<p><b>SPEAKERS</b>:
Keynote talks will give different perspectives on AI-HRI and showcase recent advances towards humans interacting with robots on everyday tasks. Moderated discussions and debates will allow participants to engage in collaborative public discussion on controversial topics and issues of interest to the AI-HRI community.</p>

<p><b>NETWORKING</b>:
A large part of this effort is to bring together a community of researchers, strengthen old connections, and build new ones. Ample time will be provided for networking and informal discussions.</p>-->


<h2>Presentation and publication</h2>

<p>
All accepted full and short papers will be presented orally and published in the proceedings through <a href=https://arxiv.org/>arXiv</a>.
Authors will be notified as to whether they have been assigned a “full-length” or “lightning” presentation slot. Authors will be notified as to whether they have been assigned a “full-length” or “lightning” presentation slot.
Authors assigned to lightning talks will be invited to participate in a poster session.
</p>



<p id="dates">

<h2>Important dates</h2>


<!-- span style="text-decoration: line-through; color: #aaaaaa;">July 17</span -->

<p> Submission:  <del>July 30, 2020</del>  August 6, 2020</p>

<p> Notification of acceptance:   September 10, 2020</p>

<!--p> Camera-ready version of Accepted Submissions: <span style="text-decoration: line-through; color: #aaaaaa;">August 29, 2019</span>.<br/>
(To be collected into a technical report for the symposium attendees.)</p>

<p> Registration deadline: September 15, 2019 (invited participants), October 13, 2019 (everyone).  -->

<p> The symposium will be held on <b>November 13-14, 2020</b>.</p>
<p> Please <a href="mailto:ai4hri@gmail.com">contact us</a> if you require additional time to submit your contribution.</p>


<p id="submission">

<h2>Submission Instructions</h2>

<p>Authors may submit under one of the following paper categories:
  <br>(The listed page limits are excluding references.)

<div class="framed">
<ul>
<li><b>Full papers (6-8 pages) </b> highlighting state-of-the-art HRI-oriented research on trust
 & explainability and other related topics.<br><br>

<li><b>Short papers (2-4 pages) </b> outlining new or controversial views on AI-HRI research or describing ongoing AI-oriented HRI research.<br><br>

<li><b>Tool papers (2-4 pages)</b> describing novel software, hardware, or datasets of interest to the AI-HRI community. </li>
</ul>
</div>

<p>Papers are to be submitted through the AAAI EasyChair site.
   Proceedings will be published through arXiv by each individual author.</p>

<p>Authors will be notified as to whether they have been assigned a full-length or 'lightning' presentation slot.
 Authors assigned to lightning talks will be invited to participate in a poster session.
 Additionally, all submitting authors will be added to the reviewer pool and may be asked to contribute to the peer-review process.</p>

<p>Please see the <a style="background-color: white; border: 1px solid black; padding: 6px 6px 6px 6px;" href="https://www.aaai.org/Publications/Templates/AuthorKit20.zip">AAAI Author Kit</a> for paper templates to ensure that your submission has proper formatting.</p>


<p style="font-weight: bold">Contributions may be submitted here:<br>
<a style="background-color: white; border: 1px solid black; padding: 6px 6px 6px 6px;" href="https://easychair.org/my/conference?conf=fss20">https://easychair.org/my/conference?conf=fss20</a></p>

<p> For any extenuating circumstances that may result in a delayed submission, please <a href="mailto:ai4hri@gmail.com">contact us</a>.</p>


<p id="diversity">
<br>


<h2>Diversity & Inclusion at AI-HRI</h2>


<!-- span style="text-decoration: line-through; color: #aaaaaa;">July 17</span -->

<p> AI-HRI is committed to growing the diversity of our community and is actively pursuing ways to make our community more inclusive.
  Our efforts include diversifying the participation among  our program committee, invited speakers, paper authors, and symposium attendees.</p>

  <p> To support attendees from under-represented groups (URGs), AI-HRI will be providing at least two complimentary registrations.
    This includes but is not limited to those who identify as Women, African American/Black, Hispanic/LatinX, Indigenous, persons with a disability, and/or LGBTQI+.
    To express your interest in receiving a complimentary registration, please <a href="https://forms.gle/J6Bt95TcAQRctfXA6">fill out this form</a>.</p>

  <p> We are also looking to expand our ability to award complimentary registrations and are looking for sponsors to help.  If you or your company is interesting in supporting our D&I initiative, please <a href="mailto:ai4hri@gmail.com">contact us</a>.</p>
  <p> If you have any other suggestions on how we can further promote diversity and inclusion at AI-HRI, please contact us at <a href="mailto:ai4hri@gmail.com">ai4hri@gmail.com</a>.</p>




<!--a href="invited_abstracts.html"> Abstracts of the invited talks. </a -->


<p id="papers">


<!-- h2><a href="https://arxiv.org/html/1809.06606">Accepted Papers</a></h2>

<p>
<b>Balancing Efficiency and Coverage in Human-Robot Dialogue Collection <a href="https://arxiv.org/abs/1810.02017">PDF</a></b>.<br>
Matthew Marge, Claire Bonial, Stephanie Lukin, Cory Hayes, Ashley Foots, Ron Artstein, Cassidy Henry, Kimberly Pollard, Carla Gordon, Felix Gervits, Anton Leuski, Susan Hill, Clare Voss and David Traum

<p>
<b>Multimodal Interactive Learning of Primitive Actions <a href="https://arxiv.org/abs/1810.00838">PDF</a></b>.<br>
Tuan Do, Nikhil Krishnaswamy, Kyeongmin Rim and James Pustejovsky

<p>
<b>Apprenticeship Bootstrapping via Deep Learning with a Safety Net for UAV-UGV Interaction <a href="https://arxiv.org/abs/1810.04344">PDF</a></b>.<br>
Hung Nguyen, Phi Vu Tran, Duy Tung Nguyen, Matthew Garratt, Kathryn Kasmarik, Michael Barlow, Sreenatha Anavatti and Hussein Abbass

<p>
<b>Deep HMResNet Model for Human Activity-Aware Robotic Systems <a href="https://arxiv.org/abs/1809.07624">PDF</a></b>.<br>
Hazem Abdelkawy, Naouel Ayari, Abdelghani Chibani, Yacine Amirat and Ferhat Attal

<p>
<b>Cycle-of-Learning for Autonomous Systems from Human Interaction <a href="https://arxiv.org/abs/1808.09572">PDF</a></b>.<br>
Nicholas Waytowich, Vinicius Goecks and Vernon Lawhern

<p>
<b>Towards a Unified Planner For Socially-Aware Navigation <a href="https://arxiv.org/abs/1810.00966">PDF</a></b>.<br>
Santosh Balajee Banisetty and David Feil-Seifer

<p>
<b>Playing Pairs with Pepper <a href="https://arxiv.org/abs/1810.07593">PDF</a></b>.<br>
Abdelrahman Yaseen and Katrin Lohan

<p>
<b>Using pupil diameter to measure Cognitive load <a href="https://arxiv.org/abs/1812.07653">PDF</a></b>.<br>
Georgios Minadakis and Katrin Lohan

<p>
<b>BubbleTouch: A Quasi-Static Tactile Skin Simulator <a href="https://arxiv.org/abs/1809.09153">PDF</a> </b>.<br>
Brayden Hollis, Stacy Patterson, Jinda Cui and Jeff Trinkle

<p>
<b>Interaction and Autonomy in RoboCup@Home and Building-Wide Intelligence <a href="https://arxiv.org/abs/1810.02919">PDF</a> </b>.<br>
Justin Hart, Harel Yedidsion, Yuqian Jiang, Nick Walker, Rishi Shah, Jesse Thomason, Aishwarya Padmakumar, Rolando Fernandez, Jivko Sinapov, Raymond Mooney and Peter Stone

<p>
<b>Adaptive Grasp Control through Multi-Modal Interactions for Assistive Prosthetic Devices <a href="http://ai-hri.github.io">PDF</a> </b>.<br>
Michelle Esponda and Thomas Howard

<p>
<b>Towards Online Learning from Corrective Demonstrations <a href="https://arxiv.org/abs/1810.01036">PDF</a> </b>.<br>
Reymundo Gutierrez, Elaine Short, Scott Niekum and Andrea Thomaz


</div !-->


<p id="program">
<br>

<h2>Confirmed Invited Speakers</h2>

<div class="framed">
<ul>
  <li> <a href="https://interactive.mit.edu/about/people/julie">Julie Shah</a> </li>
  <li> <a href="https://www.uu.nl/staff/MMAdeGraaf">Maartje de Graaf</a> </li>
  <li> <a href="https://vivo.brown.edu/display/bmalle">Bertram F. Malle</a> </li>
</ul>

</div>

<h2>Program</h2>

<br>  &nbsp;&nbsp;&nbsp;
TBA
<!--<a <a style="background-color: cyan; border: 1px solid black; padding: 6px 6px 6px 6px;" href="2019AI-HRI_Schedule.pdf">Detailed PDF version</a>-->
<br><br>

<div class="program">

<!--<h3>Day 1: Thursday, November 7, 2019</h3>

<table border=1>
<tr><td width=140>09:00 – 09:15</td>  <td> <font color="#4040A0"> Introduction and Announcements</font> </td> </tr>
<tr><td>09:15 – 10:15</td>  <td> <font color="#4040A0"> Invited Speaker: Michael Gleicher</font> </td> </tr>
<tr><td>10:15 – 10:30</td>  <td>   <font color="#4040A0"> Breakout Session: Topics and Team-ups </font> </td> </tr>
<tr><td>10:30 – 11:00</td>  <td>    <font color="#A04040">Coffee Break</font> </td> </tr>
<tr><td>11:00 – 12:30</td>  <td>   <font color="#4040A0">  Long Paper Presentations
</font>
<font color="#000000" size=2>
<br><br>
Towards A Robot Explanation System: A Survey and Our Approach to State Summarization, Storage and Querying, and Human Interface<br>
Zhao Han, Jordan Allspaw, Adam Norton, and Holly Yanco
<br><br>
Petri Net Machines for Human-Agent Interaction<br>
Christian Dondrup, Ioannis Papaioannou, and Oliver Lemon
<br><br>
Language-guided Adaptive Perception with Hierarchical Symbolic Representations for Mobile Manipulators<br>
Ethan Fahnestock, Siddharth Patki, and Thomas Howard
<br><br>
Four-Arm Manipulation via Feet Interfaces<br>
Jacob Hernandez, Walid Amanhoud, Anaïs Haget, Hannes Bleuler, Aude Billard, and Mohamed Bouri
<br><br>
Unclogging Our Arteries: Using Human-Inspired Signals to Disambiguate Navigational Intentions <br>
Justin Hart, Reuth Mirsky, Stone Tejeda, Bonny Mahajan, Jamin Goo, Kathryn Baldauf, Sydney Owen and Peter Stone
<br><br>
Automated Production of Stylized Animations for Social Robots <br>
Adrian Ball and Ross Mead
</font>

<tr><td>12:30 – 14:00</td>  <td>    <font color="#A04040">Lunch</font></td> </tr>
<tr><td>14:00 – 15:00</td>  <td>   <font color="#4040A0"> Breakout session </font> </td> </tr>
<tr><td>15:00 – 15:30</td>  <td>  <font color="#4040A0">   Lightning Talks </font>
<font color="#000000" size=2>
<br><br>
A Research Platform for Multi-Robot Dialogue with Humans <br>
Matthew Marge, Stephen Nogar, Cory Hayes, Stephanie Lukin, Jesse Bloecker, Eric Holder, and Clare Voss
 <br><br>
Fuzzy Knowledge-Based Architecture for Learning and Interaction in Social Robots <br>
Mehdi Ghayoumi and Maryam Pourebadi
 <br><br>
Multimodal Dataset of Human-Robot Hugging Interaction <br>
Kunal Bagewadi, Joseph Campbell, and Heni Ben Amor
<br><br>
Towards Development of Datasets for Human Action Understanding in Human-Robot Interaction <br>
Megan Zimmerman and Shelly Bagchi
 <br><br>
Responsive Planning and Recognition for Closed-Loop Interaction <br>
Richard Freedman, Yi Ren Fung, Roman Ganchin and Shlomo Zilberstein
 <br><br>
Adaptable Human Intention and Trajectory Prediction for Human-Robot Collaboration <br>
Abulikemu Abuduweili, Siyan Li, and Changliu Liu
</font>



</td> </tr>
<tr><td>15:30 – 16:00</td>  <td>  <font color="#A04040">  Coffee Break + <font color="#4040A0"> Poster Session</font>  </td> </tr>
<tr><td>16:00 – 17:00</td>  <td> <font color="#4040A0"> Invited Speaker: Manuela Veloso </font> </td> </tr>
<tr><td>17:00 – 17:30</td>  <td> <font color="#4040A0"> Poster Session </font> </td> </tr>
<tr><td>18:00 – 19:00</td>  <td>   <font color="#A04040"> Reception </font> </td> </tr>
</table>



<h3>Day 2: Friday, November 8, 2019</h3>

<table border=1>

<tr><td width=140>09:00 – 09:15</td>  <td> <font color="#4040A0">  Announcements</font> </td></tr>
<tr><td width=140>09:15 – 10:15</td>  <td> <font color="#4040A0">  Invited Speaker: Laura Hiatt</font> </td></tr>

<tr><td>10:15 – 10:30</td>  <td>   <font color="#4040A0"> Breakout Session: Topics and Team-ups </font> </td> </tr>
<tr><td>10:30 – 11:00</td>  <td>    <font color="#A04040">Coffee Break</font> </td> </tr>
<tr><td>11:00 – 12:30</td>  <td>   <font color="#4040A0">  Long Paper Presentations </font>
<font color="#000000" size=2>
<br><br>
Enabling Intuitive Human-Robot Teaming Using Augmented Reality and Gesture Control <br>
Jason Gregory, Christopher Reardon, Kevin Lee, Geoffrey White, Ki Ng, and Caitlyn Sims
 <br><br>
Negotiation-based Human-Robot Collaboration via Augmented Reality <br>
Kishan Chandan, Xiang Li, and Shiqi Zhang
 <br><br>
An Alert-Generation Framework for Improving Resiliency in Human-Supervised, Multi-Agent Teams <br>
Sarah Al-Hussaini, Jason M. Gregory, Shaurya Shriyam, and Satyandra K. Gupta
 <br><br>
Trust and Cognitive Load During Human-Robot Interaction <br>
Muneeb Ahmad, Jasmin Bernotat, Katrin Lohan, and Friederike Eyssel
 <br><br>
Towards an Adaptive Robot for Sports and Rehabilitation Coaching <br>
Martin Ross, Frank Broz, and Lynne Baillie
 <br><br>
Selfie Drone Stick: A Natural Interface for Quadcopter Photography <br>
Saif Alabachi, Gita Sukthankar, and Rahul Sukthankar
</font>

</td> </tr>
<tr><td>12:30 – 14:00</td>  <td>    <font color="#A04040">Lunch</font></td> </tr>
<tr><td>14:00 – 15:00</td>  <td>   <font color="#4040A0"> Invited Speaker: Matthew Marge </font> </td> </tr>
<tr><td>15:00 – 15:30</td>  <td>   <font color="#4040A0">  Lightning Talks </font>
<font color="#000000" size=2>
<br><br>
MAD-TN: A Tool for Measuring Fluency in Human-Robot Collaboration <br>
Seth Issacson, Gretchen Rice, and James Boerkoel
 <br><br>
Building Second-Order Mental Models for Human-Robot Interaction <br>
Connor Brooks and Daniel Szafir
 <br><br>
Commitments in Human-Robot Interaction <br>
Victor Fernandez Castro, Aurelie Clodic, Rachid Alami, and Elisabeth Pacherie
 <br><br>
Developing Computational Models of Social Assistance to Guide Socially Assistive Robots <br>
Jason Wilson, Seongsik Kim, Ulyana Kurylo, Joseph Cummings and Eshan Tarneja
 <br><br>
Towards Effective Human-AI Teams: The Case of Collaborative Packing <br>
Gilwoo Lee, Christoforos Mavrogiannis and Siddhartha Srinivasa
 <br><br>
An Automated Vehicle like Me? The Impact of Personality Similarities and Differences between Humans and AVs <br>
Qiaoning Zhang, Connor Esterwood, Xi Jessie Yang and Lionel Robert
</font>
 </td> </tr>
<tr><td>15:30 – 16:00</td>  <td>  <font color="#A04040">  Coffee Break + <font color="#4040A0"> Poster Session</font>  </td> </tr>
<tr><td>16:00 – 16:30</td>  <td> <font color="#4040A0"> Poster Session </font> </td> </tr>
<tr><td>16:30 – 17:30</td>  <td> <font color="#4040A0"> Breakout Session </font> </td> </tr>
<tr><td>18:00 – 19:30</td>  <td>   <font color="#A04040"> Plenary Session </font> </td> </tr>
</table>


<h3>Saturday, November 9, 2019</h3>

<table border=1>

<tr><td width=140>09:00 – 09:15</td>  <td> <font color="#4040A0">  Announcements</font> </td></tr>
<tr><td width=140>09:15–10:00</td>  <td> <font color="#4040A0">Tech Talks </font>
<font color="#000000" size=2>
<br><br>
Where is My Stuff? An Interactive System for Spatial Relations <br>
Emrah Sisbot and Jonathan Connell
 <br><br>
Solving Service Robot Tasks: UT Austin Villa@Home 2019 Team Report <br>
Rishi Shah, Yuqian Jiang, Haresh Karnan, Gilberto Briscoe-Martinez, Dominick Mulder, Ryan Gupta, Rachel Schlossman,
Marika Murphy, Justin Hart, Luis Sentis, and Peter Stone
 <br><br>
MuMMER: Socially Intelligent Human-Robot Interaction in Public Spaces <br>
Mary Ellen Foster and Olivier Canévet
</font>
</td></tr>
<tr><td>10:00–10:30</td>  <td>    <font color="#4040A0">Tech Discussion: Haves, Needs, and Wants</font> </td> </tr>
<tr><td>10:30–11:00</td>  <td>    <font color="#A04040">Coffee Break</font> </td> </tr>

<tr><td>11:00–12:00</td>  <td> <font color="#4040A0"> Future Directions and Discussion </font> </td></tr>
<tr><td>12:00–12:30</td>  <td> <font color="#4040A0"> Wrap-Up/Closing Remarks </font> </td> </tr>
</table>

</div>



<!--<p><b>The schedule of Lightning Research Talks is available <a href="https://dl.dropboxusercontent.com/u/17178057/AI-HRI%20AAAI%20FS14%20Lightning%20Schedule.pdf">here</a>.</b><br></p>-->



<p id="committee">


<h2>Organizing Committee</h2>


<p>Shelly Bagchi (National Institute of Standards and Technology),
<p>Jason R. Wilson (Franklin & Marshall College),
<p>Muneeb I. Ahmad (Heriot-Watt University),
<p>Christian Dondrup (Heriot-Watt University),
<p>Zhao Han (UMass Lowell),
<p>Justin W. Hart (University of Texas Austin),
<p>Matteo Leonetti (University of Leeds),
<p>Katrin Solveig Lohan (University of Applied Sciences Ostschweiz OST),
<p>Ross Mead (Semio),
<p>Emmanuel Senft (University of Wisconsin, Madison),
<p>Jivko Sinapov, Communications Co-Chair (Tufts University),
<p>Megan L. Zimmerman (National Institute of Standards and Technology)

<p> Contact us at <a href="mailto:ai4hri@gmail.com">ai4hri@gmail.com</a>.









<!-- p>Kalesha Bullard (<a href="mailto:ksbullard@gatech.edu">Georgia Institute of Technology</a>)</p
<p>Justin W. Hart (UT Austin)
<!--<p>Nick DePalma (<!--a href="mailto:n.depalma@samsung.com"Facebook AI Research</a>)
<p>Richard G. Freedman (Smart Information Flow Technologies and UMass Amhers)
<p>Luca Iocchi (<!--a href="mailto:iocchi@diag.uniroma1.it"Sapienza University of Rome</a>)
<p>Matteo Leonetti (University of Leeds)
<p>Katrin Lohan (<!--a href="mailto:K.Lohan@hw.ac.uk"Heriot-Watt University</a>)
<p>Ross Mead (<!--a href="mailto:ross@semio.ai"Semio</a>)
<p>Emmanuel Senft (<!--a href="mailto:emmanuel.senft@plymouth.ac.uk"Plymouth University</a>)
<p>Jivko Sinapov (Tufts University)
<p>Elin A. Topp (Lund University)
<p>Tom Williams (<!--a href="mailto:twilliams@mines.edu"Colorado School of Mines</a>)</p
-->



        <!-- TYPEKIT -->
<!-- LI: what is this?
        <script type="text/javascript" src="//use.typekit.net/ajf8ggy.js"></script>
        <script type="text/javascript">try{Typekit.load();}catch(e){}</script>
        <script src="https://rawgithub.com/ccampbell/rainbow/master/js/rainbow.min.js"></script>
        <script src="https://rawgithub.com/ccampbell/rainbow/master/js/language/generic.js"></script>
-->

    </div>

<div id="past_aihri_links">Prior Symposia: &nbsp;&nbsp;&nbsp;
    <a href="../2014/">AI-HRI 2014</a>  &nbsp;&nbsp;&nbsp;
    <a href="../2015/">AI-HRI 2015</a>  &nbsp;&nbsp;&nbsp;
    <a href="../2016/">AI-HRI 2016</a>  &nbsp;&nbsp;&nbsp;
    <a href="../2017/">AI-HRI 2017</a>  &nbsp;&nbsp;&nbsp;
    <a href="../2018/">AI-HRI 2018</a>  &nbsp;&nbsp;&nbsp;
    <a href="../2019/">AI-HRI 2019</a>

</div>

</body>
</html>
