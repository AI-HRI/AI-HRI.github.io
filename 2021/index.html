<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>AI-HRI</title>
    <meta name="viewport" content="width=device-width; initial-scale=1.0; maximum-scale=1.0;">

    <!-- Some custom styles to make things pretty. -->
    <link rel="stylesheet" type="text/css" href="https://tilomitra.github.io/prettypages/ui.css">



    <!-- Modify header colors here to customize the look and feel of the site-->
    <style>

        .header {
            background: rgb(0, 60, 120);
            margin-left: -8px;
            margin-right: -8px;
         }
        .header h1 {
            font-size:200%;
            color: white;
        }
        .header h2, .header h3 {
            font-weight:300;
            margin:0;
            color: #6DF7BD;
        }

        #past_aihri_links {
            font-size: 120%;
            background: rgb(18, 15, 66);
            color: white;
            padding: 10px 0px 10px 0px;
            text-align: center;
        }
        #past_aihri_links a {
            color: white;
            text-decoration: underline;
        }
        #past_aihri_links a:hover {
            font-weight: bold;
        }

        div.framed {
            padding-top: 15px;
            padding-bottom: 15px;
            font-size: 16px;
            border-bottom: 2px solid black;
            border-top: 2px solid black;
        }

        div.framed li {
            font-size: 18px;
        }

        div.program {
            font-size: 16px;
        }

        .main {
            margin-top: 30px; /* Add a top margin to avoid content overlay */
        }

        .navbar {
            position: fixed; /* Set the navbar to fixed position */
            top: 0px; /* Position the navbar at the top of the page */
            left: 0;
            right: 0;
            font-size: 135%;
            padding-top: 10px;
            padding-bottom: 10px;
            padding-left: 10px;
            padding-right: 50px;
            box-shadow: inset 0 0 0 50px rgb(18, 15, 66);

        }

        .navbar a {
            background: rgb(18, 15, 66);
        }

        .navbar a:hover {
            font-weight: bold;
            background: rgb(18, 15, 66);
            box-shadow: inset 0 0 0 50px rgb(18, 15, 66);
        }

        img.adaptive {
            width: 30%;
            height: auto;
        }

        .content {
            width: unset;
            max-width: 1200px;
        }

     </style>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-64202401-1', 'auto');
      ga('send', 'pageview');

    </script>

</head>

<body class='main'>

    <div id="headerMenu" class="navbar">

	    &nbsp;&nbsp;&nbsp; <b>AI-HRI 2021</b> &nbsp;&nbsp;&nbsp;

            <a href="#home">&nbsp;&nbsp;  Home  &nbsp;&nbsp;  </a>
            <a href="#speakers">&nbsp;&nbsp;  Speakers & Panelists  &nbsp;&nbsp;  </a>
            <a href="#dates">&nbsp;&nbsp;  Dates & Submission  &nbsp;&nbsp;  </a>
            <!-- a href="#submission">&nbsp;&nbsp;  Submission &nbsp;&nbsp; </a -->
            <!-- <a href="#diversity">&nbsp;&nbsp;  Diversity & Inclusion  &nbsp;&nbsp;  </a> -->
            <!-- a href="#papers">&nbsp;&nbsp;  Papers &nbsp;&nbsp; </a -->
            <a href="#program">&nbsp;&nbsp;  Program  &nbsp;&nbsp;  </a>
            <a href="#committee">&nbsp;&nbsp;  Organizers  &nbsp;&nbsp;  </a>

    </div>

<div>
    <br><br><br>
    <center>
    <img src="images/aaai.jpg" height="100" /> <br><br><br>
    </center>
</div>

<div class="header">
<center>
    <img class="adaptive" src="images/aihri_3_800w_darkbg.png" /> <br>

        <h1>Artificial Intelligence for Human-Robot Interaction <br></h1><br/><br/>

        <h2><a style="color: #CDCDA7; text-decoration: underline;" target="_blank" href="https://aaai.org/Symposia/Fall/fss21.php">AAAI Fall Symposium Series</a></h2><br/><br/>
	<h3 style="color: #DDDDA7;">Virtual, November 4-6, 2021</h3><br/>
</center>
</div>



<div class="content">

<h2>News</h2>

<p>Online registration form: <a href="https://aaaiconf.cventevents.com/fss21">aaaiconf.cventevents.com/fss21</a>.</p>

<p>10/11 — Most papers are linked to their PDFs in <a href="#program">Program</a>.</p>

<p>9/23 — <a href="#program">Program</a> is updated and most is confirmed.</p>

<p>9/23 — Our special issue was accepted to ACM Transactions on Human-Robot Interaction (THRI)! The deadline is Apr 15, 2022. We will provide more details soon.</p>

<p id="home">

<h2>Introduction</h2>

<p>
The Artificial Intelligence (AI) for Human-Robot Interaction (HRI) Symposium has been a successful venue of discussion and collaboration since 2014. During that time, these symposia provided a fertile ground for numerous collaborations and pioneered many discussions revolving trust in HRI, XAI for HRI, service robots, interactive learning, and more. This year, we aim to review the achievements of the AI-HRI community in the last decade, identify the challenges facing ahead, and welcome new researchers who wish to take part in this growing community.</p>
<p>
Taking this wide perspective, this year there will be no single theme to lead the symposium and <b>we encourage AI-HRI submissions from across disciplines and research interests.</b>
Moreover, with the rising interest in AR and VR as part of an interaction and following the difficulties in running physical experiments during the pandemic, this year we specifically encourage researchers to submit works that do not include a physical robot in their evaluation, but promote HRI research in general. In addition, acknowledging that ethics is an inherent part of the human-robot interaction, we encourage submissions of works on ethics for HRI.</p><p>
Over the course of the two-day meeting, we will host a collaborative
 forum for discussion of current efforts in AI-HRI, with additional talks focused on the topics of ethics in HRI and ubiquitous HRI.
</p>

<h3>Topics</h3>

<ul>
<li>Ubiquitous HRI, including AR and VR
<li>Ethics in HRI
<li>Trust and Explainability in HRI
<li>Architectures and systems supporting autonomous HRI
<li>Interactive task learning
<li>Interactive dialog systems and natural language
<li>Field studies, experimental, and empirical HRI
<li>Tools for autonomous HRI
<li>Robot planning and decision-making
<li>AI for social robots
<li>Fielding and deployment, and experimentation for autonomous robots
<li>Knowledge representation and reasoning to support HRI and robot tasking
</ul>

<p id="speakers">
<br>

<h2>Invited Speakers</h2>

<div class="people">
    <div>
        <img src="https://i1.rgstatic.net/ii/profile.image/278839323316227-1443491883341_Q128/Sonia-Chernova.jpg">
        <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a><br>Georgia Tech
    </div>
    <div>
        <img src="https://i1.sndcdn.com/avatars-000320344348-rwgdmz-t500x500.jpg">
        <a href="http://justinhart.net/">Justin W. Hart</a><br>UT Austin
    </div>
    <div>
        <img src="https://people.mines.edu/twilliams/wp-content/uploads/sites/161/2020/02/me.jpg">
        <a href="https://people.mines.edu/twilliams/">Tom Williams</a><br>Colorado School of Mines
    </div>
</div>


<h2>Panelists & Moderator</h2>

<div class="people">
    <div>
        <img src="images/Bio_RossMead-2-1024x1024.jpg">
        <a href="https://www.linkedin.com/in/rossmead">Ross Mead</a><br>Semio<br><span class="label">Moderator</span>
    </div>
    <div>
        <img src="https://pbs.twimg.com/profile_images/1275780786642456576/ukWf1kem.jpg">
        <a href="https://www.cc.gatech.edu/people/matthew-gombolay">Matthew Gombolay</a><br>Georgia Tech
    </div>
    <div>
        <img src="https://people.mines.edu/twilliams/wp-content/uploads/sites/161/2020/02/me.jpg">
        <a href="https://people.mines.edu/twilliams/">Tom Williams</a><br>Colorado School of Mines
    </div>
    <div>
        <img src="https://www2.eecs.berkeley.edu/risingstars/2020/participants/alves-oliveira.jpg">
        <a href="https://www.patricialvesoliveira.com/">Patrícia Alves-Oliveira</a><br>University of Washington
    </div>
    <div>
        <img src="images/Dan Grollman.jpeg">
        <a href="https://dangrollman.medium.com/">Dan Grollman</a><br>Plus One Robotics
    </div>
    <div>
        <img src="https://pbs.twimg.com/profile_images/1288522420735954946/gQGtsB5m_400x400.jpg">
        <a href="https://www.kaleshabullard.com/">Kalesha Bullard</a><br>Facebook
    </div>
    <div>
        <img src="https://www.sift.net/sites/default/files/styles/staff_full_content_photo/public/images/staff/rfreedman.jpg?itok=mXSAs8Xv">
        <a href="https://www.sift.net/staff/richard-freedman">Richard G. Freedman</a><br>SIFT
    </div>
</div>

<style>
    .people img {
        max-width: 128px;
        border-radius:  100px;
    }
    .people div {
        text-align: center;
        display: inline-block;
        color: #aaa;
        margin-bottom: 20px;

        max-width: 135px;
        vertical-align: top;
    }
    .people div + .people div {
        margin-right: 0.5rem;
    }
    .people .label {
        background: #eee;
        margin-top: 5px;
        padding: 3px;
        display: inline-block;
        font-size: smaller;
        border-radius: 9px;
    }
</style>


<p id="dates">

<h2>Important Dates</h2>

<p> Submission: August 13, 2021</p>

<p> Notification of acceptance: September 6, 2021</p>

<p> Camera-ready version of Accepted Submissions: October 9, 2021</p>

<p> Registration deadline: October 15, 2021. <a href="https://aaaiconf.cventevents.com/fss21">Register here</a>.</p>  

<p> The symposium will be held on <b>November 4-6, 2021</b>.</p>
<p> Please <a href="mailto:ai4hri@gmail.com">contact us</a> if you require additional time to submit your contribution or have any questions.</p>


<p id="submission">

<h2>Submission Instructions</h2>

<p>Authors may submit under one of the following paper categories:
  <br>(The listed page limits are excluding references.)

<div class="framed">
<ul>
<li><b>Full papers (6-8 pages) </b> highlighting state-of-the-art AI-HRI-oriented research.<br><br>

<li><b>Short papers (2-4 pages) </b> outlining new or controversial views on AI-HRI research or describing ongoing AI-oriented HRI research.<br><br>

<li><b>Tool papers (2-4 pages)</b> describing novel software, hardware, or datasets of interest to the AI-HRI community. </li>
</ul>
</div>

<p>Papers are to be submitted through <a href="https://easychair.org/my/conference?conf=fss21">the AAAI EasyChair site</a>. Our review process is single blind, so submissions do not need to be anonymized. Please see the <a style="background-color: white; border: 1px solid black; padding: 6px 6px 6px 6px;" href="https://www.aaai.org/Publications/Templates/AuthorKit21.zip">AAAI Author Kit</a> for paper templates to ensure that your submission has proper formatting.

<p>Proceedings will be published through arXiv by each individual author. A special issue has been accepted to ACM Transactions on Human-Robot Interaction (THRI) for extended versions of the symposium submissions.</p>

<p>Authors will be notified as to whether they have been assigned a full-length or 'lightning' presentation slot.
 Authors assigned to lightning talks will be invited to participate in a poster session.
 Additionally, all submitting authors will be added to the reviewer pool and may be asked to contribute to the peer-review process.</p>

<p></p>

<p> For any extenuating circumstances that may result in a delayed submission, please <a href="mailto:ai4hri@gmail.com">contact us</a>.</p>





<p id="program">
<br>

<h2>Program</h2>

<!--<a <a style="background-color: cyan; border: 1px solid black; padding: 6px 6px 6px 6px;" href="2019AI-HRI_Schedule.pdf">Detailed PDF version</a>-->
Please find the schedule below.  All times listed are in Eastern Time (GMT-4).  Full-length talks are 15 minutes and short "poster" talks are 5 minutes (not including questions).<br>
<!--<h3>Full Papers can be found in the <a href="https://arxiv.org/abs/2010.13830">arXiv proceedings</a> or in the  <a href="http://ai-hri.github.io/2020/papers/">local proceedings</a>.</h3>
Please reach out to the authors with any questions or if their paper is not available. -->
<br><br>

<style type="text/css">
    .program table { border-collapse: collapse; margin-bottom: 3em; }
    .program table td { padding: 0.5em; border: 1px solid; }

    .program table td > ul { padding-left: 0; list-style: none; }
    .program table td > ul > li { margin-bottom: 1em; }
</style>

<h3>Thursday, November 4</h3>
<div class="program">

<table><tbody><tr><td>10:00 - 10:30</td><td>Introductions and Announcements</td></tr><tr><td>10:30 - 11:30</td><td>Keynote on <b>AI-HRI</b> (Sonia Chernova)</td></tr><tr><td>11:30 - 11:45</td><td>Coffee Break</td></tr><tr><td>11:45 - 12:30</td><td>Ice-Breaker</td></tr><tr><td>12:30 - 13:30</td><td>Paper Presentations 1
    <ul><li><a href="https://arxiv.org/pdf/2110.13061">Where were my keys? -- Aggregating Spatial-Temporal Instances of Objects for Efficient Retrieval over Long Periods of Time</a><ul><li>Ifrah Idrees, Zahid Hassan, Steven Reiss and Stefanie Tellex</li></ul></li><li><a href="https://arxiv.org/pdf/2110.11075">Enabling a Social Robot to Process Social Cues to Detect when to Help a User</a><ul><li>Jason Wilson, Phyo Thuta Aung and Isabelle Boucher</li></ul></li><li><a href="https://arxiv.org/pdf/2110.04332">Using Trust for Heterogeneous Human-Robot Team Task Allocation</a><ul><li>Arsha Ali, Hebert Azevedo-Sa, Dawn Tilbury and Lionel Robert</li></ul></li><li><a href="https://arxiv.org/pdf/2109.12912">A User-Centred Framework for Explainable Artificial Intelligence in Human-Robot Interaction</a><ul><li>Marco Matarese, Francesco Rea and Alessandra Sciutti</li></ul></li><li><a href="https://arxiv.org/pdf/2110.03433">From the Head or the Heart? An Experimental Design on the Impact of Explanation on Cognitive and Affective Trust</a><ul><li>Qiaoning Zhang, Xi Jessie Yang and Lionel Robert</li></ul></li></ul>
</td></tr><tr><td>13:30 - 14:30</td><td><b>Lunch</b></td></tr><tr><td>14:30 - 15:30</td><td>Invited Talk on <strong>Ubiquitous HRI</strong> (Justin Hart)</td></tr><tr><td>15:30 - 15:45</td><td>Coffee Break</td></tr><tr><td>15:45 - 16:45</td><td>Paper Presentations 2
    <ul><li><a href="https://arxiv.org/pdf/2110.04697">An Augmented Reality Platform for Introducing Reinforcement Learning to K-12 Students with Robots</a><ul><li>Ziyi Zhang, Samuel M. Akai-Nettey, Adonai Addo, Chris Rogers and Jivko Sinapov</li></ul></li><li><a href="https://arxiv.org/pdf/2110.00751">Partner-Aware Algorithms in Decentralized Cooperative Bandit Teams</a><ul><li>Erdem Bıyık, Anusha Lalitha, Rajarshi Saha, Andrea Goldsmith and Dorsa Sadigh</li></ul></li><li><a href="https://arxiv.org/pdf/2110.03071">“Two Many Cooks”: Understanding Dynamic Human - Agent Team Communication and Perception Using Overcooked 2</a><ul><li>Andres Rosero, Faustina Dinh, Tyler Shaw, Ewart de Visser and Elizabeth Phillips</li></ul></li><li>Dehumanizing Voice Technology: Phonetic &amp; Experiential Consequences of Restricted Human-Machine Interaction<ul><li>Christian Hildebrand, Donna Hoffman and Tom Novak</li></ul></li></ul>
</td></tr><tr><td>16:45 - 17:30</td><td>Moderated Discussions</td></tr><tr><td>17:30 - 17:45</td><td>General Discussion</td></tr></tbody></table>

</div>

<h3>Friday, November 5</h3>
<div class="program">

<table><tbody><tr><td>10:00 - 11:00</td><td>Paper Presentations 3
	<ul><li><a href="https://arxiv.org/pdf/2110.04203">Toward a Human-Level Video Understanding Intelligence</a><ul><li>Yu-Jung Heo, Minsu Lee, Seong-Ho Choi, Woo Suk Choi, Minjung Shin, Minjoon Jung, Jeh-Kwang Ryu and Byoung-Tak Zhang</li></ul></li><li><a href="https://arxiv.org/pdf/2110.04192">Explaining Reward Functions to Humans for Better Human-Robot Collaboration</a><ul><li>Lindsay Sanneman and Julie Shah</li></ul></li><li><a href="https://arxiv.org/pdf/2110.04418">Moral-Trust Violation vs Performance-Trust Violation by a Robot: Which Hurts More?</a><ul><li>Zahra Rezaei Khavas, Russell Perkins, S.Reza Ahmadzadeh and Paul Robinette</li></ul></li><li><a href="https://arxiv.org/pdf/2110.04729">Humans’ Assessment of Robots as Moral Regulators: Importance of Perceived Fairness and Legitimacy</a><ul><li>Boyoung Kim and Elizabeth Phillips</li></ul></li><li><a href="https://arxiv.org/pdf/2110.06809">Trust Calibration and Trust Respect: A Method for Building Team Cohesion in Human Robot Teams</a><ul><li>Russell Perkins, Zahra Rezaeikhavas and Paul Robinette</li></ul></li></ul>
</td></tr><tr><td>11:00 - 11:40</td><td>Moderated Discussions</td></tr><tr><td>11:40 - 11:45</td><td>Short Break</td></tr><tr><td>11:45 - 12:45</td><td>Keynote on <strong>Ethics in AI-HRI</strong> (Tom Williams)</td></tr><tr><td>12:45 - 14:00</td><td><b>Lunch</b></td></tr><tr><td>14:00 - 15:00</td><td>Paper Presentations 4
	<ul><li><a href="https://arxiv.org/pdf/2108.07259">APReL: A Library for Active Preference-based Reward Learning Algorithms</a><ul><li>Erdem Bıyık, Aditi Talati and Dorsa Sadigh</li></ul></li><li><a href="https://arxiv.org/pdf/2110.03134">Improving Robot-Centric Learning from Demonstration via Personalized Embeddings</a><ul><li>Mariah Schrum, Erin Hedlund and Matthew Gombolay</li></ul></li><li><a href="https://arxiv.org/pdf/2110.04633">Credit Assignment Safety Learning from Human Demonstrations</a><ul><li>Ahalya Prabhakar and Aude Billard</li></ul></li><li><a href="https://arxiv.org/pdf/2110.04347">Towards Sample-efficient Apprenticeship Learning from Suboptimal Demonstration</a><ul><li>Letian Chen, Rohan Paleja and Matthew Gombolay</li></ul></li><li><a href="https://arxiv.org/pdf/2110.04634">Multimodal Sensory Learning for Real-time, Adaptive Manipulation</a><ul><li>Ahalya Prabhakar, Stanislas Furrer, Lorenzo Panchetti, Maxence Perret and Aude Billard  </li></ul></li></ul>
</td></tr><tr><td>15:00 - 15:45</td><td>Moderated Discussions</td></tr><tr><td>15:45 - 16:00</td><td>Coffee Break</td></tr><tr><td>16:00 - 17:00</td><td>Paper Presentations 5
    <ul><li><a href="https://arxiv.org/pdf/2108.05971">Ergonomically Intelligent Physical Human-Robot Interaction: Postural Estimation, Assessment, and Optimization</a><ul><li>Amir Yazdani, Roya Sabbagh Novin, Andrew Merryweather and Tucker Hermans</li></ul></li><li><a href="https://arxiv.org/pdf/2110.04663">Learning to Control Complex Robots Using High-Dimensional Interfaces: Preliminary Insights</a><ul><li>Jongmin M. Lee, Temesgen Gebrekristos, Dalia De Santis, Mahdieh Nejati Javaremi, Deepak Gopinath, Biraj Parikh, Ferdinando A. Mussa-Ivaldi and Brenna D. Argall</li></ul></li><li><a href="https://arxiv.org/pdf/2110.04664">Using Human-Guided Causal Knowledge for More Generalized Robot Task Planning</a><ul><li>Semir Tatlidil, Yanqi Liu, Emily Sheetz, R. Iris Bahar and Steven Sloman</li></ul></li><li><a href="https://arxiv.org/pdf/2110.04649">Interactive Hierarchical Guidance using Language</a><ul><li>Bharat Prakash, Nicholas Waytowich, Tim Oates and Tinoosh Mohsenin</li></ul></li></ul>
</td></tr><tr><td>17:00 - 17:15</td><td>General Discussion</td></tr></tbody></table>

</div>

<h3>Saturday, November 6</h3>
<div class="program">

<table><tbody><tr><td>10:00 - 11:00</td><td>Panel on <strong>the Future of AI-HRI</strong></td></tr><tr><td>11:00 - 12:00</td><td>Paper Presentations 6
    <ul><li><a href="https://arxiv.org/pdf/2110.03026">Human Capabilities as Guiding Lights for the Field of AI-HRI: Insights from Engineering Education</a><ul><li>Tom Williams and Ruchen Wen</li></ul></li><li><a href="https://arxiv.org/pdf/2110.04647">Learning to Follow Language Instructions with Compositional Policies</a><ul><li>Vanya Cohen, Geraud Nangue Tasse, Nakul Gopalan, Steven James, Matthew Gombolay, Benjamin Rosman</li></ul></li><li><a href="https://arxiv.org/pdf/2110.05186">A MultiModal Social Robot Toward Personalized Emotion Interaction</a><ul><li>Baijun Xie and Chung Hyuk Park</li></ul></li><li><a href="https://arxiv.org/pdf/2110.04441">Natural Language for Human-Robot Collaboration: Problems Beyond Language Grounding</a><ul><li>Seth Pate, Wei Xu, Ziyi Yang, Maxwell Love, Siddarth Ganguri and Lawson L.S. Wong</li></ul></li><li>What Are You Looking At? Integrating a Computational Model of Attention with a Cognitive Robotic Architecture<ul><li>Gordon Briggs, Evan Krause, Will Bridewell, Paul Bello and Matthias Scheutz</li></ul></li></ul>
</td></tr><tr><td>12:00 - 12:15</td><td>Coffee Break &amp; Poster Session</td></tr><tr><td>12:15 - 13:00</td><td>Moderated Discussions</td></tr><tr><td>13:00 - 13:45</td><td>Wrap-Up and Discussion on Future Topics</td></tr></tbody></table>

</div>




<p id="diversity">
<br>


<h2>Diversity & Inclusion at AI-HRI</h2>


<!-- span style="text-decoration: line-through; color: #aaaaaa;">July 17</span -->

<p> AI-HRI is committed to growing the diversity of our community and is actively pursuing ways to make our community more inclusive.
  Our efforts include diversifying the participation among  our program committee, invited speakers, paper authors, and symposium attendees.</p>

<p>If you are having difficulties, please contact us at <a href="mailto:ai4hri@gmail.com">ai4hri@gmail.com</a>.</p>

<!--
  <p> To support attendees from under-represented groups (URGs), AI-HRI will be providing at least two complimentary registrations.
    This includes but is not limited to those who identify as Women, African American/Black, Hispanic/LatinX, Indigenous, persons with a disability, and/or LGBTQI+.
    To express your interest in receiving a complimentary registration, please <a href="https://forms.gle/J6Bt95TcAQRctfXA6">fill out this form</a>.
	</p>

  <p> We are also looking to expand our ability to award complimentary registrations and are looking for sponsors to help.  If you or your company is interesting in supporting our D&I initiative, please <a href="mailto:ai4hri@gmail.com">contact us</a>.</p>
  <p> If you have any other suggestions on how we can further promote diversity and inclusion at AI-HRI, please contact us at <a href="mailto:ai4hri@gmail.com">ai4hri@gmail.com</a>.</p> 
 
 -->
  





<p id="committee">


<h2>Organizing Committee</h2>

<div class="people">
    <div>
        <img src="https://yt3.ggpht.com/ytc/AKedOLTx6USTxL9mRZLOy9KAMJsrKS27n_vMUJDiHJCtUDA=s176-c-k-c0x00ffffff-no-rj">
        <a href="https://sites.google.com/site/dekelreuth/">Reuth Mirsky</a><br>University of Texas, Austin
    </div>
    <div>
        <img src="https://avatars.sched.co/0/34/6953660/avatar.jpg?87b">
        <a href="https://www.nist.gov/people/megan-zimmerman">Megan L. Zimmerman</a><br>National Institute of Standards and Technology
    </div>
    <div>
        <img src="https://www.hw.ac.uk/uk/schools/img/macs/profiles/Muneeb-Ahmad.jpg">
        <a href="https://www.swansea.ac.uk/staff/science/compsci/ahmad-m-i/">Muneeb I. Ahmad</a><br>Swansea University, UK
    </div>
    <div>
        <img src="https://www.nist.gov/sites/default/files/styles/2800_x_2800_limit/public/images/2017/04/13/img_1320_1.jpg">
        <a href="https://www.nist.gov/people/shelly-bagchi">Shelly Bagchi</a><br>National Institute of Standards and Technology
    </div>
    <div>
        <img src="https://media-exp1.licdn.com/dms/image/C4D03AQHYxx3r4d1iLg/profile-displayphoto-shrink_800_800/0/1591973995470?e=1640217600&v=beta&t=WFH8dRS_9bKUD_UQdLXvEmoRFyXW9Nx9eN-UiTaKSNg">
        <a href="https://www.linkedin.com/in/felix-gervits-4a377a6a/">Felix Gervits</a><br>US Army Research Lab
    </div>
    <div>
        <img src="https://inside.mines.edu/~zhaohan/Zhao_Han.jpg">
        <a href="https://inside.mines.edu/~zhaohan/">Zhao Han</a><br>Colorado School of Mines
    </div>
    <div>
        <img src="https://i1.sndcdn.com/avatars-000320344348-rwgdmz-t500x500.jpg">
        <a href="http://justinhart.net/">Justin W. Hart</a><br>University of Texas Austin
    </div>
    <div>
        <img src="images/DanielHernandezGarciaPhoto.png">
        <a href="https://dhgarcia.github.io/">Daniel Hernández García</a><br>Heriot-Watt University
    </div>
    <div>
        <img src="https://www.kcl.ac.uk/importedimages/schools/nms/informatics/matteo-leonetti.xcad2195f.jpg">
        <a href="https://www.kcl.ac.uk/people/matteo-leonetti">Matteo Leonetti</a><br>King's College London
    </div>
    <div>
        <img src="images/Bio_RossMead-2-1024x1024.jpg">
        <a href="https://www.linkedin.com/in/rossmead">Ross Mead</a><br>Semio
    </div>
    <div>
        <img src="https://i1.rgstatic.net/ii/profile.image/1056259855896576-1628843382009_Q128/Emmanuel-Senft-2.jpg">
        <a href="https://emmanuel-senft.github.io/">Emmanuel Senft</a><br>University of Wisconsin, Madison
    </div>
    <div>
        <img src="https://facultyprofiles.tufts.edu/jivko-sinapov/photo">
        <a href="https://www.eecs.tufts.edu/~jsinapov/">Jivko Sinapov</a><br>Tufts University
    </div>
    <div>
        <img src="https://www.fandm.edu/uploads/files/458236942790430919-wilson-pic.0.504.3024.3024.one-half.jpg">
        <a href="https://fandm-cares.github.io/">Jason R. Wilson</a><br>Franklin & Marshall College
    </div>
</div>

<p> Contact us at <a href="mailto:ai4hri@gmail.com">ai4hri@gmail.com</a>.


<p style="text-align: right"> <a href="https://github.com/AI-HRI/AI-HRI.github.io/edit/master/2021/index.html">Edit this page on GitHub</a><p>
        <!-- TYPEKIT -->
<!-- LI: what is this?
        <script type="text/javascript" src="//use.typekit.net/ajf8ggy.js"></script>
        <script type="text/javascript">try{Typekit.load();}catch(e){}</script>
        <script src="https://rawgithub.com/ccampbell/rainbow/master/js/rainbow.min.js"></script>
        <script src="https://rawgithub.com/ccampbell/rainbow/master/js/language/generic.js"></script>
-->

    </div>

<div id="past_aihri_links">Prior Symposia: &nbsp;&nbsp;&nbsp;
    <a href="../2014/">AI-HRI 2014</a>  &nbsp;&nbsp;&nbsp;
    <a href="../2015/">AI-HRI 2015</a>  &nbsp;&nbsp;&nbsp;
    <a href="../2016/">AI-HRI 2016</a>  &nbsp;&nbsp;&nbsp;
    <a href="../2017/">AI-HRI 2017</a>  &nbsp;&nbsp;&nbsp;
    <a href="../2018/">AI-HRI 2018</a>  &nbsp;&nbsp;&nbsp;
    <a href="../2019/">AI-HRI 2019</a>  &nbsp;&nbsp;&nbsp;
	<a href="../2020/">AI-HRI 2020</a>

</div>

</body>
</html>
